{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 85%; }\n",
       "    div#maintoolbar-container { width: 99%; } </style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make the screen bigger!\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(data=\"\"\" <style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 85%; }\n",
    "    div#maintoolbar-container { width: 99%; } </style> \"\"\"))\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "\n",
    "homedir = os.getcwd()\n",
    "\n",
    "\n",
    "# pandas display options\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "pd.set_option('display.precision', 1)    # set number of significant digits to diplay n pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_HRU = ['LULC','HRU','GIS','SUB','MGT','MON','AREAkm2','PRECIPmm','SNOFALLmm','SNOMELTmm','IRRmm','PETmm','ETmm','SW_INITmm',\n",
    "'SW_ENDmm','PERCmm','GW_RCHGmm','DA_RCHGmm','REVAPmm','SA_IRRmm','DA_IRRmm','SA_STmm','DA_STmm','SURQ_GENmm','SURQ_CNTmm','TLOSSmm',\n",
    "'LATQGENmm','GW_Qmm','WYLDmm','DAILYCN','TMP_AVdgC','TMP_MXdgC','TMP_MNdgC','SOL_TMPdgC','SOLARMJ/m2','SYLDt/ha','USLEt/ha','N_APPkg/ha',\n",
    "'P_APPkg/ha','NAUTOkg/ha','PAUTOkg/ha','NGRZkg/ha','PGRZkg/ha','NCFRTkg/ha','PCFRTkg/ha','NRAINkg/ha','NFIXkg/ha','F-MNkg/ha','A-MNkg/ha','A-SNkg/ha',\n",
    "'F-MPkg/ha','AO-LPkg/ha','L-APkg/ha','A-SPkg/ha','DNITkg/ha','NUPkg/ha','PUPkg/ha','ORGNkg/ha','ORGPkg/ha','SEDPkg/ha','NSURQkg/ha','NLATQkg/ha','NO3Lkg/ha',\n",
    "'NO3GWkg/ha','SOLPkg/ha','P_GWkg/ha','W_STRS','TMP_STRS','N_STRS','P_STRS','BIOMt/ha','LAI','YLDt/ha','BACTPct','BACTLPct','WTABCLIm','WTABSOLm','SNOmm','CMUPkg/ha',\n",
    "'CMTOTkg/ha','QTILEmm','TNO3kg/ha','LNO3kg/ha','GW_Q_Dmm','LATQCNTmm','TVAPkg/ha']\n",
    "\n",
    "colnames_RCH = ['whaaaaa', 'RCH',  'GIS',  'MON',  'AREAkm2',  'FLOW_INcms',   'FLOW_OUTcms',  'EVAPcms',  'TLOSScms', 'SED_INtons',   \n",
    "            'SED_OUTtons',  'SEDCONCmg/L',  'ORGN_INkg',    'ORGN_OUTkg',   'ORGP_INkg',    'ORGP_OUTkg',   'NO3_INkg', \n",
    "            'NO3_OUTkg',    'NH4_INkg', 'NH4_OUTkg',    'NO2_INkg', 'NO2_OUTkg',    'MINP_INkg',    'MINP_OUTkg',   'CHLA_INkg',    \n",
    "            'CHLA_OUTkg',   'CBOD_INkg',    'CBOD_OUTkg',   'DISOX_INkg',   'DISOX_OUTkg',  'SOLPST_INmg',  'SOLPST_OUTmg', 'SORPST_INmg',  \n",
    "            'SORPST_OUTmg', 'REACTPSTmg',   'VOLPSTmg', 'SETTLPSTmg',   'RESUSP_PSTmg', 'DIFFUSEPSTmg', 'REACBEDPSTmg', 'BURYPSTmg',    \n",
    "            'BED_PSTmg',    'BACTP_OUTct',  'BACTLP_OUTct', 'CMETAL#1kg',   'CMETAL#2kg',   'CMETAL#3kg',   'TOTNkg',   'TOTPkg',   \n",
    "            'NO3ConcMg/l',  'WTMPdegc']\n",
    "\n",
    "colnames_SUB = ['trash', 'SUB',  'GIS',  'MON',  'AREAkm2',  'PRECIPmm', 'SNOMELTmm',    'PETmm',    'ETmm', 'SWmm', 'PERCmm',   'SURQmm',   \n",
    "            'GW_Qmm',   'WYLDmm',   'SYLDt/ha', 'ORGNkg/ha',    'ORGPkg/ha',    'NSURQkg/ha',   'SOLPkg/ha',    'SEDPkg/ha',    \n",
    "            'LATQ(mm)', 'LATNO3kg/ha',  'GWNO3kg/ha',   'CHOLAmic/L',   'CBODUmg/L',    'DOXQmg/L', 'TNO3kg/ha',    'QTILEmm',  'TVAPkg/ha']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Process output HRU file from Daily run into yearly run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILEPATH = r'C:\\Users\\cshul\\Desktop\\GitHub_repo_copies\\DL_watershed\\Q_SWAT_workflow_testing\\2_Afono\\model\\Nuuuli_test1\\Scenarios\\Default\\TxtInOut'\n",
    "itername    = \"iter1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" now open the file.cio file in the folder and change the IPRINT: print code (month, day, year) code to 2 \"\"\"\n",
    "os.chdir(OUTFILEPATH)\n",
    "\n",
    "with open(os.path.join('.', 'file.cio'), 'r') as fin:   # open file \n",
    "    data = fin.read().splitlines(True)\n",
    "\n",
    "Stuff1 = data[0:58]\n",
    "New_print_time =    '               2    | IPRINT: print code (month, day, year)\\n'\n",
    "Stuff2 = data[59:68]\n",
    "New_HRU1_vars =     '   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\\n'\n",
    "stuff3 = data[69]\n",
    "New_HRU1_print =     '   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\\n'\n",
    "stuff4 = data[71:]\n",
    "\n",
    "Stuff1.append(New_print_time)\n",
    "Stuff1.extend(Stuff2)\n",
    "Stuff1.append(New_HRU1_vars)\n",
    "Stuff1.append(stuff3)\n",
    "Stuff1.append(New_HRU1_print)\n",
    "Stuff1.extend(stuff4)\n",
    "\n",
    "with open(os.path.join('.', 'file.cio'), 'w') as fout:  # write new file.cio\n",
    "    fout.writelines(Stuff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''run SWAT yearly resolution'''\n",
    "\n",
    "os.chdir(OUTFILEPATH)\n",
    "subprocess.call('SWAT.exe', shell=True)\n",
    "\n",
    "# this modifies the File CIO file to run as Daily again\n",
    "\n",
    "with open(os.path.join('.', 'file.cio'), 'r') as fin:   # open file \n",
    "    data = fin.read().splitlines(True)\n",
    "\n",
    "    \n",
    "\"\"\" now open the file.cio file in the folder and change the IPRINT: print code back to 1 \"\"\"\n",
    "Stuff1 = data[0:58]\n",
    "New_print_time =    '               1    | IPRINT: print code (month, day, year)\\n'\n",
    "Stuff2 = data[59:68]\n",
    "New_HRU1_vars =     '   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\\n'\n",
    "stuff3 = data[69]\n",
    "New_HRU1_print =     '   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\\n'\n",
    "stuff4 = data[71:]\n",
    "\n",
    "Stuff1.append(New_print_time)\n",
    "Stuff1.extend(Stuff2)\n",
    "Stuff1.append(New_HRU1_vars)\n",
    "Stuff1.append(stuff3)\n",
    "Stuff1.append(New_HRU1_print)\n",
    "Stuff1.extend(stuff4)\n",
    "\n",
    "with open(os.path.join('.', 'file.cio'), 'w') as fout:  # write new file.cio\n",
    "    fout.writelines(Stuff1)\n",
    "\n",
    "# back to home-dir\n",
    "os.chdir(homedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILE_HRU_yr = os.path.join(OUTFILEPATH, \"output.hru\")\n",
    "listo = []\n",
    "\n",
    "with open(OUTFILE_HRU_yr) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=' ', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        listo.append(row)\n",
    "    da_listo = listo[9:]        # cut off the headder line BS\n",
    "\n",
    "data = da_listo            # just th\n",
    "\n",
    "for i in data:\n",
    "    splitit = i[5].split(\".\")               # this little blok is because SWAT Fd up the Mon column and stuck it onto the area col, why?\n",
    "    i[5] = splitit[0]\n",
    "    i.insert(6, float('0.' + splitit[-1]))  # the bugs and inconsistant formatting in this model are truely mind blowing, the developers of this must be stoned...\n",
    "\n",
    "df = pd.DataFrame(data, columns=colnames_HRU)\n",
    "\n",
    "Ave_frame = df[df['MON'] == \"3\"]\n",
    "Ave_frame = Ave_frame.reset_index(drop=True)    # make index start at 1\n",
    " \n",
    "cols = Ave_frame.columns\n",
    "Ave_frame[cols] = Ave_frame[cols].apply(pd.to_numeric, errors='coerce', axis=1)  # make the columns numeric not strings \n",
    "\n",
    "interestedparamsHRU_mm = ['PRECIPmm','ETmm', 'GW_RCHGmm', 'SURQ_GENmm', 'LATQGENmm', 'GW_Qmm', 'GW_Q_Dmm', 'DA_RCHGmm', 'REVAPmm']\n",
    "interestedparamsHRU_kgpha = ['NSURQkg/ha','NLATQkg/ha', 'NO3GWkg/ha', 'NO3Lkg/ha', \"NCFRTkg/ha\", 'N_APPkg/ha', 'F-MNkg/ha', 'DNITkg/ha', 'NUPkg/ha']\n",
    "\n",
    "area_m2 = Ave_frame['AREAkm2']*1000000\n",
    "area_ha = Ave_frame['AREAkm2']*100\n",
    "\n",
    "ColList = []; Val_Lst = []\n",
    "for i in interestedparamsHRU_mm: \n",
    "    p = sum(((Ave_frame[i]*0.001)*area_m2)/365)     # scale by area and convert the mm values to m3/day of water \n",
    "    ColList.append(i)  ; Val_Lst.append(p)\n",
    "\n",
    "for j in interestedparamsHRU_kgpha:\n",
    "    m = sum(((area_ha*Ave_frame[j])))\n",
    "    ColList.append(j) ; Val_Lst.append(m)\n",
    "    \n",
    "Summary_frameHRU = pd.DataFrame({'a_Variables':ColList,  'b_HRU_value':Val_Lst})\n",
    "#Summary_frameHRU\n",
    "\n",
    "Summary_frameHRU.to_csv(os.path.join(OUTFILEPATH, 'Iterations', itername, 'Daily_HRU_summary_frame.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process originally Daily resolution HRU output file (Looong run time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILEPATH = r'C:\\Users\\cshuler\\Desktop\\FALU_SWAT_Folder\\Nuts_calibration5\\GiantPeach_1nut_TESTMOD.Sufi2.SwatCup'\n",
    "itername = 'MOD_solNO3_5'\n",
    "\n",
    "OUTFILE = os.path.join(OUTFILEPATH, \"output.hru\")\n",
    "\n",
    "Startdate = \"20120101\"\n",
    "OGdate = datetime(year=int(Startdate[0:4]), month=int(Startdate[4:6]), day=int(Startdate[6:8]))\n",
    "\n",
    "\n",
    "# actual column names since they are poorly delimeted in SWAT output file...\n",
    "\n",
    "listo = []\n",
    "\n",
    "with open(OUTFILE) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=' ', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        listo.append(row)\n",
    "    data = listo[9:]        # cut off the headder line BS\n",
    "\n",
    "for i in data:\n",
    "    splitit = i[5].split(\".\")               # this little blok is because SWAT Fd up the Mon column and stuck it onto the area col, why?\n",
    "    i[5] = splitit[0]\n",
    "    i.insert(6, float('0.' + splitit[-1]))  # the bugs and inconsistant formatting in this model are truely mind blowing, the developers of this must be stoned...    \n",
    "\n",
    "df = pd.DataFrame(data, columns=colnames_HRU)  # make into dataframe\n",
    "\n",
    "cols = df.columns\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce', axis=1)  # make the columns numeric not strings |\n",
    "\n",
    "\n",
    "# just split out the relevant columns to work with \n",
    "mm_cols = ['LULC','HRU','GIS','SUB','MON','AREAkm2','PRECIPmm', 'ETmm', 'PERCmm','GW_RCHGmm','DA_RCHGmm','REVAPmm', 'SURQ_GENmm', 'LATQGENmm','GW_Qmm']\n",
    "kgpha_cols = ['LULC','HRU','GIS','SUB','MON','AREAkm2', 'N_APPkg/ha', 'NCFRTkg/ha','NRAINkg/ha','NFIXkg/ha','F-MNkg/ha','A-MNkg/ha','DNITkg/ha','NUPkg/ha','NSURQkg/ha','NLATQkg/ha','NO3Lkg/ha','LNO3kg/ha', 'NO3GWkg/ha']\n",
    "\n",
    "mm_frame = df[mm_cols]\n",
    "kgpha_frame = df[kgpha_cols]\n",
    "\n",
    "\n",
    "# make values absolute in m3 of water per day or in kgN per day\n",
    "interested_mm_cols = ['PRECIPmm', 'ETmm', 'PERCmm','GW_RCHGmm','DA_RCHGmm','REVAPmm', 'SURQ_GENmm', 'LATQGENmm','GW_Qmm']\n",
    "interested_kgpha_cols = ['N_APPkg/ha', 'NCFRTkg/ha','NRAINkg/ha','NFIXkg/ha','F-MNkg/ha','A-MNkg/ha','DNITkg/ha','NUPkg/ha','NSURQkg/ha','NLATQkg/ha','NO3Lkg/ha','LNO3kg/ha', 'NO3GWkg/ha']\n",
    "\n",
    "mm_frame2 = mm_frame.copy()\n",
    "for i in interested_mm_cols:\n",
    "    new_name = i[:-2]+\"_m3pd\"   #make new column headding \n",
    "    mm_frame2[new_name]= (mm_frame[i]*0.001)*(mm_frame['AREAkm2']*1000000)\n",
    "    del mm_frame2[i]\n",
    "    \n",
    "kgpha_frame2 = kgpha_frame.copy()\n",
    "for i in interested_kgpha_cols:\n",
    "    new_name = i[:-2]+\"_kgpd\"   #make new column headding \n",
    "    kgpha_frame2[new_name]= (kgpha_frame[i])*(kgpha_frame['AREAkm2']*100)\n",
    "    del kgpha_frame2[i]\n",
    "\n",
    "\n",
    "# consolidate the data into yearly averages for each HRU (water data )\n",
    "Yearly_ave_Nflux_Water = pd.DataFrame(columns = mm_frame2.columns) # bland dataframe to concat to \n",
    "HUR_LIST  = mm_frame2['HRU'].unique()   # list of the HRUs\n",
    "for i in HUR_LIST:\n",
    "    Isolate_HRU = mm_frame2[mm_frame2['HRU'] == i]\n",
    "    Average_HRU = Isolate_HRU.groupby('MON').mean()\n",
    "    Preserve_area = Isolate_HRU['AREAkm2'].mean()\n",
    "    Consldate_HRU = Average_HRU.groupby('HRU').sum()\n",
    "\n",
    "    Consldate_HRU['AREAkm2'] = Preserve_area\n",
    "    \n",
    "    Yearly_ave_Nflux_Water = pd.concat([Yearly_ave_Nflux_Water, Consldate_HRU])\n",
    "\n",
    "Yearly_ave_Nflux_Water = Yearly_ave_Nflux_Water.reset_index(drop=False)    # make index start at 1\n",
    "Yearly_ave_Nflux_Water = Yearly_ave_Nflux_Water.rename(columns={'index': 'HRU_index'})\n",
    "\n",
    "\n",
    "# consolidate the data into yearly averages for each HRU (Nutrient data )\n",
    "Yearly_ave_Nflux_Nuts = pd.DataFrame(columns = kgpha_frame2.columns) # bland dataframe to concat to \n",
    "HUR_LIST  = kgpha_frame2['HRU'].unique()   # list of the HRUs\n",
    "for i in HUR_LIST:\n",
    "    Isolate_HRU = kgpha_frame2[kgpha_frame2['HRU'] == i]\n",
    "    Average_HRU = Isolate_HRU.groupby('MON').mean()\n",
    "    Preserve_area = Isolate_HRU['AREAkm2'].mean()\n",
    "    Consldate_HRU = Average_HRU.groupby('HRU').sum()\n",
    "\n",
    "    Consldate_HRU['AREAkm2'] = Preserve_area\n",
    "    \n",
    "    Yearly_ave_Nflux_Nuts = pd.concat([Yearly_ave_Nflux_Nuts, Consldate_HRU])\n",
    "\n",
    "Yearly_ave_Nflux_Nuts = Yearly_ave_Nflux_Nuts.reset_index(drop=False)    # make index start at 1\n",
    "Yearly_ave_Nflux_Nuts = Yearly_ave_Nflux_Nuts.rename(columns={'index': 'HRU_index'})\n",
    "\n",
    "# put together summary frames now that they are in an average annual format\n",
    "interestedparamsHRU_mm = ['DA_RCHG_m3pd', 'ET_m3pd', 'PERC_m3pd', 'PRECIP_m3pd', 'REVAP_m3pd', 'GW_Q_m3pd',  'GW_RCHG_m3pd','LATQGEN_m3pd','SURQ_GEN_m3pd']\n",
    "interestedparamsHRU_kgpha = ['NCFRTkg/_kgpd', 'NFIXkg/_kgpd', 'NLATQkg/_kgpd', 'NO3GWkg/_kgpd', 'NO3Lkg/_kgpd', 'DNITkg/_kgpd',\n",
    "       'NRAINkg/_kgpd', 'NSURQkg/_kgpd', 'NUPkg/_kgpd', 'N_APPkg/_kgpd']\n",
    "\n",
    "ColList_Wat = []; Val_Lst_Wat = []\n",
    "for j in interestedparamsHRU_mm:\n",
    "    m = sum(((Yearly_ave_Nflux_Water[j]/365)))\n",
    "    ColList_Wat.append(j) ; Val_Lst_Wat.append(m)\n",
    "\n",
    "ColList_Nut = []; Val_Lst_Nut = []\n",
    "for i in interestedparamsHRU_kgpha: \n",
    "    p = sum(Yearly_ave_Nflux_Nuts[i])     # scale by area and convert the mm values to m3/day of water \n",
    "    ColList_Nut.append(i)  ; Val_Lst_Nut.append(p)\n",
    "\n",
    "Summary_frame_dailyHRU_water = pd.DataFrame({'a_Variables':ColList_Wat,  'b_HRU_value':Val_Lst_Wat})\n",
    "Summary_frame_dailyHRU_nuts = pd.DataFrame({'a_Variables':ColList_Nut,  'b_HRU_value':Val_Lst_Nut})\n",
    "\n",
    "Daily_HRU_summary_frame = Summary_frame_dailyHRU_water.merge(Summary_frame_dailyHRU_nuts, how = 'outer', on='a_Variables')\n",
    "\n",
    "Daily_HRU_summary_frame.to_csv(os.path.join(OUTFILEPATH, 'Iterations',  itername, 'Daily_HRU_summary_frame.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing daily resolution .RCH files to get single day measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILEPATH =  r'C:\\Users\\cshuler\\Desktop\\FALU_SWAT_Folder\\Nuts_calibration4\\Good_at_cal1_stage\\JonJon_1nut_no_flo.Sufi2.SwatCup'\n",
    "\n",
    "\n",
    "OUTFILE = os.path.join(OUTFILEPATH, \"output.rch\")\n",
    "\n",
    "\n",
    "listo = []\n",
    "\n",
    "with open(OUTFILE) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=' ', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        listo.append(row)\n",
    "    data = listo[9:]        # cut off the headder line BS\n",
    "    \n",
    "df = pd.DataFrame(data, columns=colnames_RCH)  # make into dataframe\n",
    "# clean some trash up\n",
    "del df['whaaaaa'] \n",
    "cols = df.columns\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce', axis=1)  # make the columns numeric not strings \n",
    "\n",
    "\n",
    "Startdate = \"20120101\"\n",
    "OGdate = datetime(year=int(Startdate[0:4]), month=int(Startdate[4:6]), day=int(Startdate[6:8]))\n",
    "\n",
    "RCH_pile = {}\n",
    "\n",
    "for i in range(1,27):\n",
    "    keynam = \"RCH_{}\".format(i)\n",
    "    RCH_pile[keynam] = df[df['RCH'] == i]\n",
    "    RCH_pile[keynam]  = RCH_pile[keynam] .reset_index(drop=True)    # make index start at 1\n",
    "    RCH_pile[keynam]  = RCH_pile[keynam] .reset_index(drop=False)    # pull out index value\n",
    "    RCH_pile[keynam]['date'] = pd.to_datetime(RCH_pile[keynam]['index'], unit='d', origin = OGdate )  # make a date column based on the index as a day index\n",
    "    \n",
    "    # use this to pull out specific days of interest from the RCH file\n",
    "\n",
    "dayofinterest = RCH_pile['RCH_22'][RCH_pile['RCH_22']['date'] == '2014-07-04 00:00:00' ]\n",
    "dayofinterest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process NO-obs files. \n",
    "### This is getting the 95ppu_g file into an average annual list \n",
    "\n",
    "note for SWAT cup the HRU output file col numbers for each variable are: \n",
    "\n",
    "NSURQ = col 60\n",
    "NLATQ = col 61\n",
    "NO3L = col 62\n",
    "NO3GW - col 63\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILEPATH_95pp = r'C:\\Users\\cshuler\\Desktop\\FALU_SWAT_Folder\\Nuts_calibration4\\JonJon_1nut_no_flo.Sufi2.SwatCup\\SUFI2.OUT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NSURQ': [3308.4344547168366, 4385.5651568444464],\n",
       " 'NLATQ': [332.35842257405926, 910.87223987687992],\n",
       " 'NO3GW': [21.17238519053247, 36.312868137705436],\n",
       " 'NO3L': [3461.8393361006374, 5409.3206174416155]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this portion opens ut the actual HRU files to calculate the areas and multiply the ppu by Ha\n",
    "HRU_filepath = OUTFILEPATH_95pp[:-10]\n",
    "OUTFILE_HRU_95pp = os.path.join(HRU_filepath, \"output.hru\")\n",
    "listo = []\n",
    "with open(OUTFILE_HRU_95pp) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=' ', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        listo.append(row)\n",
    "    data = listo[9:]        # cut off the headder line BS\n",
    "\n",
    "for i in data:\n",
    "    splitit = i[5].split(\".\")               # this little blok is because SWAT Fd up the Mon column and stuck it onto the area col, why?\n",
    "    i[5] = splitit[0]\n",
    "    i.insert(6, float('0.' + splitit[-1]))  # the bugs and inconsistant formatting in this model are truely mind blowing, the developers of this must be stoned...\n",
    "\n",
    "df = pd.DataFrame(data, columns=colnames_HRU) \n",
    "\n",
    "Ave_frame = df[df['MON'] == \"3\"]\n",
    "Ave_frame = Ave_frame.reset_index(drop=True)    # make index start at 1\n",
    "\n",
    "\n",
    "# now open the 95ppu_g file for processing\n",
    "da_95ppu_g_file = os.path.join(OUTFILEPATH_95pp, '95ppu_g_No_Obs.txt')\n",
    "listo = []\n",
    "with open(da_95ppu_g_file) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=' ', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        listo.append(row)\n",
    "    data = listo[1:]        # cut off the headder line BS\n",
    "    \n",
    "df = pd.DataFrame(data, columns=['Stname', 'L95PPU', 'U95PPU', ''])  # make into dataframe (note for some reason extra space is getting counted as extra column, thus the blank column at the emd)\n",
    "Ncols = ['L95PPU', 'U95PPU']\n",
    "df[Ncols] = df[Ncols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "ALL_Vars_95ppu = df.groupby('Stname').mean()\n",
    "ALL_Vars_95ppu =  ALL_Vars_95ppu.reset_index(drop=False)    # make index start at 1\n",
    "\n",
    "variable_list = ['NSURQ', 'NLATQ', 'NO3GW', 'NO3L']\n",
    "\n",
    "\n",
    "\n",
    "All_var_95s = {}\n",
    "for i in variable_list: \n",
    "    i_frame = ALL_Vars_95ppu[ALL_Vars_95ppu['Stname'].str.contains(i)].copy()\n",
    "   # i_frame['HRU'] = ( i_frame['Stname']).apply(lambda x: int(x.replace('.','_').split('_')[1])) # pulls out the HRU number from the txt\n",
    "   # i_frame.sort_values('HRU')                   # sort on the HRU number to prepare for area multiplication\n",
    "    i_frame =  i_frame.reset_index(drop=True)    # apparenetly the multiplication goes by the indes so needs to be corrected  (this might not be needed?)\n",
    "    i_frame['Area'] = Ave_frame['AREAkm2']*100   # go from KG/ha to KG\n",
    "    i_frame['L95PPU_kgpd'] = i_frame['Area'] * i_frame['L95PPU']\n",
    "    i_frame['U95PPU_kgpd'] = i_frame['Area'] * i_frame['U95PPU']\n",
    "    \n",
    "    All_var_95s[i] = [i_frame['L95PPU_kgpd'].sum(), i_frame['U95PPU_kgpd'].sum()]\n",
    "\n",
    "All_var_95s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NSURQ': [3308.4344547168366, 4385.5651568444464],\n",
       " 'NLATQ': [332.35842257405926, 910.87223987687992],\n",
       " 'NO3GW': [21.17238519053247, 36.312868137705436],\n",
       " 'NO3L': [3461.8393361006374, 5409.3206174416155]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_var_95s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (depreciated) YEARLY resolution files \n",
    "### to generate yearly files dont forget\n",
    "\n",
    "- 1: change the run iterations to run the \"best\" one\n",
    "- 2: change the file CIO to print at yearly intervals \n",
    "- 3: make sure it prints the hru files by changing aly 1s to 0s in the print options\n",
    "- 4: change the sufi_run bat to print at yearly intervals\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Depreciated) Process yearly resolution output HRU file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_Variables</th>\n",
       "      <th>b_HRU_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRECIPmm</td>\n",
       "      <td>20218.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETmm</td>\n",
       "      <td>7626.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GW_RCHGmm</td>\n",
       "      <td>2414.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SURQ_GENmm</td>\n",
       "      <td>4355.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LATQGENmm</td>\n",
       "      <td>5630.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GW_Qmm</td>\n",
       "      <td>1774.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GW_Q_Dmm</td>\n",
       "      <td>630.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DA_RCHGmm</td>\n",
       "      <td>639.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>REVAPmm</td>\n",
       "      <td>356.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NSURQkg/ha</td>\n",
       "      <td>559.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NLATQkg/ha</td>\n",
       "      <td>1093.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NO3GWkg/ha</td>\n",
       "      <td>20.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NO3Lkg/ha</td>\n",
       "      <td>4275.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NCFRTkg/ha</td>\n",
       "      <td>762.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>N_APPkg/ha</td>\n",
       "      <td>2.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>F-MNkg/ha</td>\n",
       "      <td>3111.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DNITkg/ha</td>\n",
       "      <td>14141.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NUPkg/ha</td>\n",
       "      <td>6638.190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_Variables  b_HRU_value\n",
       "0     PRECIPmm    20218.131\n",
       "1         ETmm     7626.481\n",
       "2    GW_RCHGmm     2414.722\n",
       "3   SURQ_GENmm     4355.163\n",
       "4    LATQGENmm     5630.409\n",
       "5       GW_Qmm     1774.760\n",
       "6     GW_Q_Dmm      630.377\n",
       "7    DA_RCHGmm      639.731\n",
       "8      REVAPmm      356.757\n",
       "9   NSURQkg/ha      559.778\n",
       "10  NLATQkg/ha     1093.928\n",
       "11  NO3GWkg/ha       20.833\n",
       "12   NO3Lkg/ha     4275.354\n",
       "13  NCFRTkg/ha      762.754\n",
       "14  N_APPkg/ha        2.793\n",
       "15   F-MNkg/ha     3111.236\n",
       "16   DNITkg/ha    14141.703\n",
       "17    NUPkg/ha     6638.190"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTFILEPATH = r'C:\\Users\\cshuler\\Desktop\\FALU_SWAT_Folder\\Nuts_calibration3\\Frankie_1nut_wFlow_SENSitivity.Sufi2.SwatCup'\n",
    "OUTFILE_HRU_yr = os.path.join(OUTFILEPATH, \"output.hru\")\n",
    "\n",
    "# actual column names since they are poorly delimeted in SWAT output file...\n",
    "\n",
    "listo = []\n",
    "\n",
    "with open(OUTFILE_HRU_yr) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=' ', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        listo.append(row)\n",
    "    da_listo = listo[9:]        # cut off the headder line BS\n",
    "\n",
    "data = da_listo            # just th\n",
    "\n",
    "for i in data:\n",
    "    splitit = i[5].split(\".\")               # this little blok is because SWAT Fd up the Mon column and stuck it onto the area col, why?\n",
    "    i[5] = splitit[0]\n",
    "    i.insert(6, float('0.' + splitit[-1]))  # the bugs and inconsistant formatting in this model are truely mind blowing, the developers of this must be stoned...\n",
    "\n",
    "df = pd.DataFrame(data, columns=colnames_HRU)\n",
    "\n",
    "Ave_frame = df[df['MON'] == \"3\"]\n",
    "Ave_frame = Ave_frame.reset_index(drop=True)    # make index start at 1\n",
    " \n",
    "cols = Ave_frame.columns\n",
    "Ave_frame[cols] = Ave_frame[cols].apply(pd.to_numeric, errors='coerce', axis=1)  # make the columns numeric not strings \n",
    "\n",
    "interestedparamsHRU_mm = ['PRECIPmm','ETmm', 'GW_RCHGmm', 'SURQ_GENmm', 'LATQGENmm', 'GW_Qmm', 'GW_Q_Dmm', 'DA_RCHGmm', 'REVAPmm']\n",
    "interestedparamsHRU_kgpha = ['NSURQkg/ha','NLATQkg/ha', 'NO3GWkg/ha', 'NO3Lkg/ha', \"NCFRTkg/ha\", 'N_APPkg/ha', 'F-MNkg/ha', 'DNITkg/ha', 'NUPkg/ha']\n",
    "\n",
    "area_m2 = Ave_frame['AREAkm2']*1000000\n",
    "area_ha = Ave_frame['AREAkm2']*100\n",
    "\n",
    "ColList = []; Val_Lst = []\n",
    "for i in interestedparamsHRU_mm: \n",
    "    p = sum(((Ave_frame[i]*0.001)*area_m2)/365)     # scale by area and convert the mm values to m3/day of water \n",
    "    ColList.append(i)  ; Val_Lst.append(p)\n",
    "\n",
    "for j in interestedparamsHRU_kgpha:\n",
    "    m = sum(((area_ha*Ave_frame[j])))\n",
    "    ColList.append(j) ; Val_Lst.append(m)\n",
    "    \n",
    "Summary_frameHRU = pd.DataFrame({'a_Variables':ColList,  'b_HRU_value':Val_Lst})\n",
    "Summary_frameHRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process YEARLY resolution output SUB file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILE = os.path.join(OUTFILEPATH, \"output.sub\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "listo = []\n",
    "with open(OUTFILE) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=' ', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        listo.append(row)\n",
    "    data = listo[9:]        # cut off the headder line BS\n",
    "\n",
    "for i in data:\n",
    "    splitit = i[3].split(\".\")               # this little blok is because SWAT Fd up the Mon column and stuck it onto the area col, why?\n",
    "    i[3] = splitit[0]\n",
    "    i.insert(4, float('0.' + splitit[-1]))  # the bugs and inconsistant formatting in this model are truely mind blowing, the developers of this must be stoned...\n",
    "    \n",
    "df = pd.DataFrame(data, columns=colnames_SUB)\n",
    "Ave_frame = df[df['MON'] == \"3\"]\n",
    "Ave_frame = Ave_frame.reset_index(drop=True)    # make index start at 1\n",
    "cols = Ave_frame.columns\n",
    "Ave_frame[cols] = Ave_frame[cols].apply(pd.to_numeric, errors='coerce', axis=1)  # make the columns numeric not strings \n",
    "\n",
    "Ave_frame\n",
    "\n",
    "interestedparamsHRU_mm = ['PRECIPmm','ETmm', 'PERCmm', 'SURQmm', 'LATQ(mm)', 'GW_Qmm'  ]\n",
    "interestedparamsHRU_kgpha = ['NSURQkg/ha', 'LATNO3kg/ha',  'GWNO3kg/ha' ]\n",
    "\n",
    "area_m2 = Ave_frame['AREAkm2']*1000000\n",
    "area_ha = Ave_frame['AREAkm2']*100\n",
    "\n",
    "ColList = []; Val_Lst = []\n",
    "for i in interestedparamsHRU_mm: \n",
    "    p = sum(((Ave_frame[i]*0.001)*area_m2)/365)     # scale by area and convert the mm values to m3/day of water \n",
    "    ColList.append(i)  ; Val_Lst.append(p)\n",
    "\n",
    "for j in interestedparamsHRU_kgpha:\n",
    "    m = sum(((area_ha*Ave_frame[j])))\n",
    "    ColList.append(j) ; Val_Lst.append(m)\n",
    "    \n",
    "\n",
    "Summary_frameSUB = pd.DataFrame({'a_Variables':ColList,  'b_HRU_value':Val_Lst})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge and chec cohesivness of output SUB and Output HRU based on yearly files\n",
    "\n",
    "yearly_HRU_SUB_summary_frame= Summary_frameSUB.merge(Summary_frameHRU, how = 'outer', on='a_Variables')\n",
    "#Output_stats.to_csv(os.path.join(OUTFILEPATH, 'Output_stats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
